{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhxuciedu/CS175/blob/master/pytorch-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7FKQCFzXDnGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_w92gMaP6N1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check Package Versions"
      ]
    },
    {
      "metadata": {
        "id": "uYr2YRtWPkel",
        "colab_type": "code",
        "outputId": "fbe5ccf8-2839-4dbc-ea99-0246e48dfcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "print('__Python VERSION:', sys.version)\n",
        "print('__PyTorch VERSION:', torch.__version__)\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__Python VERSION: 3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "__PyTorch VERSION: 1.0.1.post2\n",
            "__CUDNN VERSION: 7402\n",
            "__Number CUDA Devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Eq_6EZ0QM23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PyTorch\n",
        "What is PyTorch?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "* A replacement for numpy to use the power of GPUs\n",
        "* a deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cSa2TTQfQ3nS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to numpy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "\n",
        "Construct a 5x3 matrix, uninitialized"
      ]
    },
    {
      "metadata": {
        "id": "xTW9C9zVRLWy",
        "colab_type": "code",
        "outputId": "639363a3-0d7f-4b1c-96de-2b5db58e6097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.2516e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 1.4013e-45],\n",
            "        [1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [3.8016e-39, 2.0893e+20, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i74pPBySRRDZ",
        "colab_type": "code",
        "outputId": "20615421-59ab-43ee-8fa9-82e5ad1a37e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# get its size\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.3493e-01, 7.8662e-01, 7.4520e-01],\n",
            "        [4.4676e-01,        nan, 9.9131e-01],\n",
            "        [8.0851e-01, 6.4072e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [4.2417e-01, 2.0893e+20, 5.9098e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O0xeSB-3Rd1L",
        "colab_type": "code",
        "outputId": "4faa6804-187a-42d9-979e-e5606e512ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Addition: in-place\n",
        "y.add_(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.3493e-01, 7.8662e-01, 7.4520e-01],\n",
              "        [4.4676e-01,        nan, 9.9131e-01],\n",
              "        [8.0851e-01, 6.4072e+02, 4.3066e+21],\n",
              "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
              "        [4.2417e-01, 2.0893e+20, 5.9098e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QagJi5H9YT_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create tensors"
      ]
    },
    {
      "metadata": {
        "id": "zF881O3lYfwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# random\n",
        "v = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
        "v = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
        "v = torch.randperm(4)   \n",
        "\n",
        "# ones\n",
        "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
        "v = torch.ones(10)              # A tensor of size 10 containing all ones\n",
        "v = torch.ones(2, 1, 2, 1)      # Size 2x1x2x1\n",
        "v = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
        "\n",
        "# zeros\n",
        "v = torch.zeros(10) \n",
        "\n",
        "# range of values\n",
        "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
        "v = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
        "\n",
        "# linear or log scale\n",
        "v = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
        "v = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0_vX6QFbP9r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dot product, component-wide product, matrix multiplication, "
      ]
    },
    {
      "metadata": {
        "id": "Hbf5A2rTYonK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dot product of 2 tensors\n",
        "r = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # 14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-AZEEfEYosW",
        "colab_type": "code",
        "outputId": "87244745-3a0f-4bac-b8e0-70d8e2883b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# component-wise product\n",
        "torch.Tensor([4, 2])* torch.Tensor([3, 1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "bnfFZpz4a0JG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Matrix x Matrix\n",
        "# Size 2x4\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 4)\n",
        "r = torch.mm(mat1, mat2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9fNQ8Aw-ahBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Batch Matrix x Matrix\n",
        "# Size 10x3x5\n",
        "batch1 = torch.randn(10, 3, 4)\n",
        "batch2 = torch.randn(10, 4, 5)\n",
        "r = torch.bmm(batch1, batch2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zygHVhSba0eN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Squeeze and unsqueeze"
      ]
    },
    {
      "metadata": {
        "id": "vylLWkFfaicW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
        "r = torch.squeeze(t)     # Size 2x2\n",
        "r = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
        "\n",
        "# Un-squeeze a dimension\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "r = torch.unsqueeze(x, 0)       # Size: 1x3\n",
        "r = torch.unsqueeze(x, 1)       # Size: 3x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6gEsNF3a-26",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transpose\n"
      ]
    },
    {
      "metadata": {
        "id": "TwCePtvPa_hO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86f11f5-f08b-4170-ee6a-5642bb71157e"
      },
      "cell_type": "code",
      "source": [
        "# Transpose dim 0 and 1\n",
        "v = torch.randn(3,2)\n",
        "r = torch.transpose(v, 0, 1)\n",
        "print(r.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G6wj7JQJRna5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Bridge\n",
        "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
        "\n",
        "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "Converting torch Tensor to numpy Array"
      ]
    },
    {
      "metadata": {
        "id": "M-V3P-KeOdFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a numpy array.\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the torch tensor to a numpy array.\n",
        "z = y.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DrxFA9zrOhcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Conversion\n",
        "a = np.array([1, 2, 3])\n",
        "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
        "\n",
        "b = v.numpy()                   # Tensor to numpy\n",
        "b[1] = -1                       # Numpy and Tensor share the same memory\n",
        "assert(a[1] == b[1])            # Change Numpy will also change the Tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkrFAPSzYDLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshape tensor"
      ]
    },
    {
      "metadata": {
        "id": "TVJAK82AYB78",
        "colab_type": "code",
        "outputId": "007f7582-81a4-42f4-fc78-df3af6cf9222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Tensor resizing\n",
        "x = torch.randn(2, 3)            # Size 2x3\n",
        "y = x.view(6)                    # Resize x to size 6\n",
        "z = x.view(-1, 2)                # Size 3x2\n",
        "print(y.shape, z.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6]) torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cfoEcojSYTra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJnuUJgeSH5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###CUDA Tensors\n",
        "\n",
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "\n",
        "Tensors can be moved onto GPU using the .cuda function."
      ]
    },
    {
      "metadata": {
        "id": "IPUVPxqbSP_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "\n",
        "x = torch.rand(3,2)\n",
        "y = torch.rand(3,2)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUYQkqCUSiRT",
        "colab_type": "code",
        "outputId": "5887c7d4-16d1-46fc-cea0-ab5fd86219bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "x"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5451, 0.3420],\n",
              "        [0.1150, 0.9795],\n",
              "        [0.5707, 0.6249]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "N20kEqktSQKm",
        "colab_type": "code",
        "outputId": "bf64dcd4-a141-4db3-ad4b-a94b6426936b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "y"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7567, 0.9499],\n",
              "        [0.1165, 0.3316],\n",
              "        [0.7169, 0.1606]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "1mS3kiy9UNoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Autograd: automatic differentiation\n",
        "\n",
        "Central to all neural networks in PyTorch is autograd, a core torch package for automatic differentiation. \n",
        "\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
        "\n",
        "Let us see this in more simple terms with some examples."
      ]
    },
    {
      "metadata": {
        "id": "PmxgzX_6U4rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create an variable\n",
        "x = torch.ones((2,2), requires_grad=True)\n",
        "\n",
        "# Do an operation of variable:\n",
        "y = x + 2\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdNxo2rxU4zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Gradients\n",
        "# ---------\n",
        "# let's backprop now\n",
        "# ``out.backward()`` is equivalent to doing ``out.backward(torch.Tensor([1.0]))``\n",
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNK-RRBmU43f",
        "colab_type": "code",
        "outputId": "9e37cbba-140c-4218-a958-a5fcc5675bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# print gradients d(out)/dx\n",
        "#\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUDiTPCeWGlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out`` *Variable* $o$.\n",
        "We have that: $o = \\frac{1}{4}\\sum_i z_i$, \n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$\n",
        "\n",
        "Therefore,\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$$ hence\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$"
      ]
    },
    {
      "metadata": {
        "id": "bKL_ex-DWs_L",
        "colab_type": "code",
        "outputId": "0ac440c6-1d5b-42c5-b43c-3d05cab2a3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# You can do many crazy things with autograd!\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  -19.0446, -1363.2463,   615.8981], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmSVgbJNWyqu",
        "colab_type": "code",
        "outputId": "fefb44da-f63e-472a-fdeb-d865d760742d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mQ5oVt1kFv6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic autograd example 1 "
      ]
    },
    {
      "metadata": {
        "id": "Lx-5ce4DE2y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mcy6p4nSE5Yt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build a computational graph.\n",
        "y = w * x + b    # y = 2 * x + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gzfF4EDBGyJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute gradients.\n",
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3hIZDh1GrJn",
        "colab_type": "code",
        "outputId": "6644d264-f509-443e-e605-ed7872f84a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Print out the gradients.\n",
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iiS-D364E6JC",
        "colab_type": "code",
        "outputId": "3b63df8f-2f17-46a3-d691-036c4d3b86a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y.detach().numpy()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "ahapqf3VF8Fn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic autograd example 2  "
      ]
    },
    {
      "metadata": {
        "id": "lgah0xn0GCxA",
        "colab_type": "code",
        "outputId": "6a0fa5ff-3df4-475e-afa9-657c0a6f4969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3]) torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oiQkdoJXGLeJ",
        "colab_type": "code",
        "outputId": "cfaca1b4-18cc-4f38-e5d8-b77cff3ad8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "print ('w: ', linear.weight)\n",
        "print ('b: ', linear.bias)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 0.2923, -0.3317,  0.4008],\n",
            "        [ 0.5509,  0.5610,  0.3034]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([0.1883, 0.2975], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IvOuGobUG_c4",
        "colab_type": "code",
        "outputId": "6e553523-cfeb-4334-a296-845b03169ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "loss = torch.sum((linear(x)-y)**2)/y.shape[0]\n",
        "print('loss: ', loss.data.numpy())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  3.5154366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Jg-jZqxIswR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIJ9YkofIszl",
        "colab_type": "code",
        "outputId": "a14f9462-0c5e-4582-ba51-a117c4342958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('w grad: ', linear.weight.grad)\n",
        "print('b grad: ', linear.bias.grad)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad:  tensor([[ 1.4770, -0.6500,  0.5289],\n",
            "        [ 0.5974,  0.6427,  0.3403]])\n",
            "b grad:  tensor([ 1.1086, -0.3205])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPtT7MCXJJsj",
        "colab_type": "code",
        "outputId": "d04d5a97-e004-4e41-dae4-b5042e87c871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# check grad\n",
        "print('w grad:', (linear(x)-y).transpose(0,1).mm(x)/y.shape[0]*2)\n",
        "print('b grad:', 2*torch.mean(linear(x)-y, dim=0))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad: tensor([[ 1.4770, -0.6500,  0.5289],\n",
            "        [ 0.5974,  0.6427,  0.3403]], grad_fn=<MulBackward0>)\n",
            "b grad: tensor([ 1.1086, -0.3205], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yy7Cv9ugMN0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###. Basic autograd example 3"
      ]
    },
    {
      "metadata": {
        "id": "hon-LU88MN6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "linear = nn.Linear(3, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltmT6QfoFMal",
        "colab_type": "code",
        "outputId": "3edb5dbc-b95a-4a90-d1da-346eac735305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)\n",
        "\n",
        "# 1-step gradient descent.\n",
        "optimizer.step()\n",
        "\n",
        "# You can also perform gradient descent at the low level.\n",
        "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  2.252901792526245\n",
            "dL/dw:  tensor([[-0.3655,  0.6044, -1.0335],\n",
            "        [ 0.5968,  0.1730,  0.0765]])\n",
            "dL/db:  tensor([ 0.8729, -0.3719])\n",
            "loss after 1 step optimization:  2.224485397338867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WO2btHYRjJ6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input pipeline, Data loader"
      ]
    },
    {
      "metadata": {
        "id": "YC-xoV6kPmlm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download and construct CIFAR-10 dataset.\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "# Fetch one data pair (read data from disk).\n",
        "image, label = train_dataset[0]\n",
        "print (image.size())\n",
        "print (label)\n",
        "\n",
        "# Data loader (this provides queues and threads in a very simple way).\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# When iteration starts, queue and thread start to load data from files.\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "# Mini-batch images and labels.\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Actual usage of the data loader is as below.\n",
        "for images, labels in train_loader:\n",
        "    # Training code should be written here.\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bI16kN0tjnRl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input pipeline for custom dataset"
      ]
    },
    {
      "metadata": {
        "id": "TLfA6_yGjlwF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ================================================================== #\n",
        "#                  Input pipeline for custom dataset                 #\n",
        "# ================================================================== #\n",
        "\n",
        "# You should build your custom dataset as below.\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        # TODO\n",
        "        # 1. Initialize file paths or a list of file names. \n",
        "        pass\n",
        "    def __getitem__(self, index):\n",
        "        # TODO\n",
        "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "        # 3. Return a data pair (e.g. image and label).\n",
        "        pass\n",
        "    def __len__(self):\n",
        "        # You should change 0 to the total size of your dataset.\n",
        "        return 0 \n",
        "\n",
        "# You can then use the prebuilt data loader. \n",
        "custom_dataset = CustomDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olrd4PlTjgv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "xRsDNLcKjfGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ================================================================== #\n",
        "#                           Pretrained model                         #\n",
        "# ================================================================== #\n",
        "\n",
        "# Download and load the pretrained ResNet-18.\n",
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# If you want to finetune only the top layer of the model, set as below.\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the top layer for finetuning.\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
        "\n",
        "# Forward pass.\n",
        "images = torch.randn(64, 3, 224, 224)\n",
        "outputs = resnet(images)\n",
        "print (outputs.size())     # (64, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9VbbrBlBjY6P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save and load the model    "
      ]
    },
    {
      "metadata": {
        "id": "qfYBD7T_jW6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save and load the entire model.\n",
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "# Save and load only the model parameters (recommended).\n",
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gx1gFIdtjdcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}